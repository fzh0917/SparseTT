test:
  track:
    exp_name: &TEST_NAME "sparsett-swin-fulldata-val"
    exp_save: &TEST_SAVE "work_dir/val"
    pipeline:
      name: "SparseTTTracker"
      SparseTTTracker:
        test_lr: 0.95
        window_influence: 0.21
        penalty_k: 0.04
        total_stride: 16
        score_size: 19
        z_size: 127
        x_size: 289
        normalize: True
        norm_mean: [ 123.675, 116.28, 103.53 ]
        norm_std: [ 58.395, 57.12, 57.375 ]
        to_rgb: True
    tester:
      names: ["GOT10kTester",] # (VOTTester|GOT10kTester|LaSOTTester)
      GOT10kTester:
        exp_name: *TEST_NAME
        exp_save: *TEST_SAVE
        subsets: ["val"]  # (val|test)
        data_root: "datasets/GOT-10k"
        device_num: &VAL_DEVICE_NUM 1
      OTBTester:
        exp_name: *TEST_NAME
        exp_save: *TEST_SAVE
        device_num: *VAL_DEVICE_NUM
        subsets: [ "otb2015" ]
      UAVTester:
        exp_name: *TEST_NAME
        exp_save: *TEST_SAVE
        device_num: *VAL_DEVICE_NUM
        subsets: [ "UAV123" ]
train:
  track:
    exp_name: &TRAIN_NAME "sparsett-swin-fulldata-train"
    exp_save: &TRAIN_SAVE "work_dir/train"
    num_processes: 4
    model:
      use_sync_bn: True
      task_model:
        name: "SiamTrack"
        SiamTrack:
          in_channels: 384
          mid_channels: &MID_CHANNELS 256
          amp: &amp False
          pretrain_model_path: ""
      backbone:
        name: "SwinTransformer"
        SwinTransformer:
          embed_dims: 96
          depths: [2, 2, 6, 2]
          num_heads: [3, 6, 12, 24]
          out_indices: (2, )
          window_size: 7
          mlp_ratio: 4
          qkv_bias: True
          qk_scale: None
          drop_rate: 0.0
          attn_drop_rate: 0.0
          drop_path_rate: 0.2
          patch_norm: True
          with_cp: False
          convert_weights: True
          pretrained: 'models/swin/swin_tiny_patch4_window7_224.pth'
      neck:
        name: "TransformerNeck"
        TransformerNeck:
          mid_channels_model: *MID_CHANNELS
          mid_channels_ffn: 2048
          num_heads: 8
          num_encoder_layers: 2
          num_decoder_layers: 2
          prob_dropout: 0.1
          f_z_size: 8
          f_x_size: &TRAIN_SCORE_SIZE 19
          top_k: 32
      task_head:
        name: "DoubleConvFCBBoxHead"
        DoubleConvFCBBoxHead:
          in_channels: 512  # MID_CHANNELS * 2
          num_convs: 7
          x_size: &TRAIN_X_SIZE 289
          score_size: *TRAIN_SCORE_SIZE
          total_stride: &TOTAL_STRIDE 16
      losses:
        names: [
                 "FocalLossFC",
                 "IOULossFC",
                 "FocalLossConv",
                 "IOULossConv",
        ]
        FocalLossFC:
          name: "cls_fc"
          alpha: 0.75
          gamma: 2.0
          weight: 1.4  # 2 * 0.7
        IOULossFC:
          name: "reg_fc"
          weight: 0.6  # 2 * (1 - 0.7)
        FocalLossConv:
          name: "cls_conv"
          alpha: 0.75
          gamma: 2.0
          weight: 0.5  # 2.5 * (1 - 0.8)
        IOULossConv:
          name: "reg_conv"
          weight: 2.0  # 2.5 * 0.8
# ==================================================
    data:
      exp_name: *TRAIN_NAME
      exp_save: *TRAIN_SAVE
      num_epochs: &NUM_EPOCHS 20
      minibatch: &MINIBATCH 32  # 256
      num_workers: 32
      nr_image_per_epoch: &NR_IMAGE_PER_EPOCH 600000
      pin_memory: False
      datapipeline:
        name: "RegularDatapipeline"
      sampler:
        name: "TrackPairSampler"
        TrackPairSampler:
          negative_pair_ratio: 0.33
        submodules:
          dataset:
            names: [
              "TrackingNetDataset",
              "COCODataset",
              "GOT10kDataset",
              "DETDataset",
              "VIDDataset",
              "LaSOTDataset",
              ]
            GOT10kDataset: &GOT10KDATASET_CFG
              ratio: 0.2
              max_diff: 100
              dataset_root: "datasets/GOT-10k"
              subset: "train"
            GOT10kDatasetFixed: *GOT10KDATASET_CFG  # got10k dataset with exclusion of unfixed sequences
            LaSOTDataset:
              ratio: 0.3
              max_diff: 100
              dataset_root: "datasets/LaSOT"
              subset: "train"
              check_integrity: false
            VIDDataset:
              ratio: 0.2
              max_diff: 100
              dataset_root: "datasets/ILSVRC2015"
              subset: "train_val"
            COCODataset:
              ratio: 0.07
              dataset_root: "datasets/COCO"
              subsets: ["train2017",]
            DETDataset:
              ratio: 0.08
              dataset_root: "datasets/ILSVRC2015"
              subset: "train"
            TrackingNetDataset:
              ratio: 0.65 # set to 0.65 if all chunks are available
              max_diff: 100
              dataset_root: "datasets/TrackingNet"
              subset: "train" # "train"
              check_integrity: false  # no need to check integrity for visualization purpose
          filter:
            name: "TrackPairFilter"
            TrackPairFilter:
              max_area_rate: 0.6
              min_area_rate: 0.001
              max_ratio: 10
      transformer:
        names: ["RandomCropTransformer", ]
        RandomCropTransformer:
          max_scale: 0.3
          max_shift: 0.4
          z_size: 127
          x_size: *TRAIN_X_SIZE
      target:
        name: "DenseboxTarget"
        DenseboxTarget:
          total_stride: *TOTAL_STRIDE
          score_size: *TRAIN_SCORE_SIZE
          x_size: *TRAIN_X_SIZE
          normalize: True
          norm_mean: [123.675, 116.28, 103.53]
          norm_std: [58.395, 57.12, 57.375]
          to_rgb: True
    trainer:
      name: "RegularTrainer"
      RegularTrainer:
        exp_name: *TRAIN_NAME
        exp_save: *TRAIN_SAVE
        max_epoch: *NUM_EPOCHS
        minibatch: *MINIBATCH
        nr_image_per_epoch: *NR_IMAGE_PER_EPOCH
        snapshot: ""
      monitors:
        names: ["TextInfo", "TensorboardLogger"]
        TextInfo:
          {}
        TensorboardLogger:
          exp_name: *TRAIN_NAME
          exp_save: *TRAIN_SAVE

# ==================================================
    optim:
      optimizer:
        name: "AdamW"
        SGD:
          # to adjust learning rate, please modify "start_lr" and "end_lr" in lr_policy module bellow
          amp: *amp
          momentum: 0.9
          weight_decay: 0.0001
          minibatch: *MINIBATCH
          nr_image_per_epoch: *NR_IMAGE_PER_EPOCH
          lr_policy:
          - >
            {
            "name": "LinearLR",
            "start_lr": 0.000001,
            "end_lr": 0.08,
            "max_epoch": 1
            }
          - >
            {
            "name": "CosineLR",
            "start_lr": 0.08,
            "end_lr": 0.000001,
            "max_epoch": 19
            }
          lr_multiplier:
          - >
            {
            "name": "backbone",
            "regex": "basemodel",
            "ratio": 0.1
            }
          - >
            {
            "name": "other",
            "regex": "^((?!basemodel).)*$",
            "ratio": 1
            }
        AdamW:
          # to adjust learning rate, please modify "start_lr" and "end_lr" in lr_policy module bellow
          amp: *amp
          lr: 1e-4
          weight_decay: 0.0001
          minibatch: *MINIBATCH
          nr_image_per_epoch: *NR_IMAGE_PER_EPOCH
          lr_policy:
          - >
            {
            "name": "MultiStageLR",
            "lr_stages": [[10, 1e-4], [15, 1e-5], [20, 1e-6]]
            }
          lr_multiplier:
          - >
            {
            "name": "backbone",
            "regex": "basemodel",
            "ratio": 0.1
            }
          - >
            {
            "name": "other",
            "regex": "^((?!basemodel).)*$",
            "ratio": 1
            }
#      grad_modifier:
#        name: "DynamicFreezer"
#        DynamicFreezer:
#          schedule:
#          - >
#            {
#            "name": "isConv",
#            "regex": "basemodel.*\\.conv\\.",
#            "epoch": 0,
#            "freezed": true
#            }
#          - >
#            {
#            "name": "isConvStage4",
#            "regex": "basemodel\\.Mixed_6.*\\.conv\\.",
#            "epoch": 10,
#            "freezed": false
#            }
#          - >
#            {
#            "name": "isConvStage3",
#            "regex": "basemodel\\.Mixed_5.*\\.conv\\.",
#            "epoch": 10,
#            "freezed": false
#            }
